{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f11507",
   "metadata": {},
   "source": [
    "# Diffusion -- diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a540e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "diffusers 是一款由huggingface开发的生成式模型调用库，可以便捷调用相应的模型。  \n",
    "在下面的部分中，我将演示如何使用diffusers开展实验，祝各位学习愉快😉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faac6bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## DDPM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122f224",
   "metadata": {},
   "source": [
    "diffusers可以有两种调用方式，详细内容可以见[website](https://www.llamafactory.cn/huggingface-docs/diffusers/using-diffusers/write_own_pipeline.html)\n",
    "\n",
    "第一种就是调用高集成的pipeline，调用简洁，但可拓展性差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb78047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# Run a demo\n",
    "model_id = \"google/ddpm-bedroom-256\"\n",
    "ddpm = DDPMPipeline.from_pretrained(model_id).to(\"cuda\")\n",
    "# image = ddpm().images[0]\n",
    "# image.save(\"bedroom.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b89a9f",
   "metadata": {},
   "source": [
    "第二种方式是将其拆分出 Model 和 Scheduler，调用相对复杂，但是可拓展性强。后面的实验都使用这一种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dee5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "\n",
    "model_id = \"google/ddpm-bedroom-256\"\n",
    "scheduler = DDPMScheduler.from_pretrained(model_id)\n",
    "model = UNet2DModel.from_pretrained(model_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set denoise steps\n",
    "scheduler.set_timesteps(50)\n",
    "scheduler.timesteps\n",
    "# Generate noise\n",
    "sample_size = model.config.sample_size\n",
    "noise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise step by step\n",
    "input = noise\n",
    "\n",
    "for t in scheduler.timesteps:\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    input = previous_noisy_sample\n",
    "    \n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41a7b9",
   "metadata": {},
   "source": [
    "### Exper1\n",
    "我们将探索 $\\hat{x}_0 = \\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\cdot \\sigma_\\theta(x_t, \\ t)}{\\sqrt{ \\bar{\\alpha_t}}}$ 以及 `input` 的生成 Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_text_to_image(image_path, output_path, title, save=False):\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 36)\n",
    "    text_position = (10,10)\n",
    "    draw.text(text_position, title, font=font, fill='white')\n",
    "    if save: \n",
    "        image.save(output_path)\n",
    "    return image\n",
    "\n",
    "def savefig(input, name):\n",
    "    from PIL import Image\n",
    "    image = (input / 2 + 0.5).clamp(0, 1).squeeze()\n",
    "    image = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "scheduler.set_timesteps(250)\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "os.makedirs(\"results1\", exist_ok=True)\n",
    "\n",
    "for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    \n",
    "    alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "    \n",
    "    x0_hat = (input - (1 - alpha_cumprod_t).sqrt() * noisy_residual) / alpha_cumprod_t.sqrt()\n",
    "    \n",
    "    # visualize\n",
    "    shape = x0_hat.shape\n",
    "    white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "    result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0_hat.cpu()], dim=3)\n",
    "    savefig(result, f\"results1/img{index}.png\")\n",
    "    \n",
    "    input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "\n",
    "savefig(input, \"final1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90205e21",
   "metadata": {},
   "source": [
    "### Optional\n",
    "我们可以从生成的结果中，挑选一部分steps，粘贴在一起，方便可视化Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bafc2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拼接完成，已保存至 output.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_list = ['results3/final-%03d.png'%(index*50) for index in range(1, 6)]\n",
    "\n",
    "\n",
    "def vertical_stitch(image_paths, output_path):\n",
    "    images = [add_text_to_image(path, None, path[9:-4], False) for path in image_paths]\n",
    "    \n",
    "    widths = [img.width for img in images]\n",
    "    if len(set(widths)) > 1:\n",
    "        raise ValueError(\"所有图片的宽度必须一致\")\n",
    "    \n",
    "    total_height = sum(img.height for img in images)\n",
    "    width = images[0].width \n",
    "\n",
    "    new_image = Image.new('RGB', (width, total_height))\n",
    "    \n",
    "    current_height = 0\n",
    "    for img in images:\n",
    "        new_image.paste(img, (0, current_height))\n",
    "        current_height += img.height\n",
    "    \n",
    "    new_image.save(output_path)\n",
    "    print(f\"拼接完成，已保存至 {output_path}\")\n",
    "\n",
    "\n",
    "vertical_stitch(img_list, \"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127265c",
   "metadata": {},
   "source": [
    "我们将 $x_0$ 固定住，进行试验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74832d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "scheduler.set_timesteps(250)\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "x0 = Image.open(\"final1.png\")\n",
    "to_tensor = transforms.ToTensor()\n",
    "x0 = to_tensor(x0)\n",
    "x0 = x0*2-1\n",
    "x0 = x0.to(\"cuda\").unsqueeze(0)\n",
    "\n",
    "os.makedirs(\"results2\", exist_ok=True)\n",
    "\n",
    "for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "    alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = (input-alpha_cumprod_t.sqrt()*x0)/(1-alpha_cumprod_t).sqrt()\n",
    "    \n",
    "    shape = x0.shape\n",
    "    white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "    result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0.cpu()], dim=-1)\n",
    "    savefig(result, f\"results2/img{index}.png\")\n",
    "    \n",
    "    input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "\n",
    "savefig(input, \"final2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444d46",
   "metadata": {},
   "source": [
    "### Exper2\n",
    "接下来我们将探索当 denoise steps 改变时，图像生成质量会发生怎样的改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(scheduler, input, model, save_dir=None, is_record=False)->torch.tensor:\n",
    "    assert save_dir, \"Please write down save dir!\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "        with torch.no_grad():\n",
    "            noisy_residual = model(input, t).sample\n",
    "        \n",
    "        if is_record:\n",
    "            alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "            x0_hat = (input - (1 - alpha_cumprod_t).sqrt() * noisy_residual) / alpha_cumprod_t.sqrt()\n",
    "            # visualize\n",
    "            shape = x0_hat.shape\n",
    "            white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "            result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0_hat.cpu()], dim=3)\n",
    "            savefig(result, os.path.join(save_dir, \"/img%03d.png\"%(index)))\n",
    "        \n",
    "        input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "timesteps = [index for index in range(250, 0, -50)]\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "for timestep in tqdm(timesteps):\n",
    "    scheduler.set_timesteps(timestep)\n",
    "    output = sample(scheduler, input, model, \"results3\", False)\n",
    "    savefig(output, \"results3/final-%03d.png\"%(timestep))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
