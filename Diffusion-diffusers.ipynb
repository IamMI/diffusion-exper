{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f11507",
   "metadata": {},
   "source": [
    "# Diffusion -- diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a540e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "diffusers æ˜¯ä¸€æ¬¾ç”±huggingfaceå¼€å‘çš„ç”Ÿæˆå¼æ¨¡åž‹è°ƒç”¨åº“ï¼Œå¯ä»¥ä¾¿æ·è°ƒç”¨ç›¸åº”çš„æ¨¡åž‹ã€‚  \n",
    "åœ¨ä¸‹é¢çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨diffuserså¼€å±•å®žéªŒï¼Œç¥å„ä½å­¦ä¹ æ„‰å¿«ðŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faac6bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## DDPM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122f224",
   "metadata": {},
   "source": [
    "diffuserså¯ä»¥æœ‰ä¸¤ç§è°ƒç”¨æ–¹å¼ï¼Œè¯¦ç»†å†…å®¹å¯ä»¥è§[website](https://www.llamafactory.cn/huggingface-docs/diffusers/using-diffusers/write_own_pipeline.html)\n",
    "\n",
    "ç¬¬ä¸€ç§å°±æ˜¯è°ƒç”¨é«˜é›†æˆçš„pipelineï¼Œè°ƒç”¨ç®€æ´ï¼Œä½†å¯æ‹“å±•æ€§å·®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb78047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# Run a demo\n",
    "model_id = \"google/ddpm-bedroom-256\"\n",
    "ddpm = DDPMPipeline.from_pretrained(model_id).to(\"cuda\")\n",
    "# image = ddpm().images[0]\n",
    "# image.save(\"bedroom.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b89a9f",
   "metadata": {},
   "source": [
    "ç¬¬äºŒç§æ–¹å¼æ˜¯å°†å…¶æ‹†åˆ†å‡º Model å’Œ Schedulerï¼Œè°ƒç”¨ç›¸å¯¹å¤æ‚ï¼Œä½†æ˜¯å¯æ‹“å±•æ€§å¼ºã€‚åŽé¢çš„å®žéªŒéƒ½ä½¿ç”¨è¿™ä¸€ç§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dee5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "\n",
    "model_id = \"google/ddpm-bedroom-256\"\n",
    "scheduler = DDPMScheduler.from_pretrained(model_id)\n",
    "model = UNet2DModel.from_pretrained(model_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set denoise steps\n",
    "scheduler.set_timesteps(50)\n",
    "scheduler.timesteps\n",
    "# Generate noise\n",
    "sample_size = model.config.sample_size\n",
    "noise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise step by step\n",
    "input = noise\n",
    "\n",
    "for t in scheduler.timesteps:\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    input = previous_noisy_sample\n",
    "    \n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41a7b9",
   "metadata": {},
   "source": [
    "### Exper1\n",
    "æˆ‘ä»¬å°†æŽ¢ç´¢ $\\hat{x}_0 = \\frac{x_t-\\sqrt{1-\\bar{\\alpha}_t}\\cdot \\sigma_\\theta(x_t, \\ t)}{\\sqrt{ \\bar{\\alpha_t}}}$ ä»¥åŠ `input` çš„ç”Ÿæˆ Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_text_to_image(image_path, output_path, title, save=False):\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 36)\n",
    "    text_position = (10,10)\n",
    "    draw.text(text_position, title, font=font, fill='white')\n",
    "    if save: \n",
    "        image.save(output_path)\n",
    "    return image\n",
    "\n",
    "def savefig(input, name):\n",
    "    from PIL import Image\n",
    "    image = (input / 2 + 0.5).clamp(0, 1).squeeze()\n",
    "    image = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()\n",
    "    image = Image.fromarray(image)\n",
    "    image.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "scheduler.set_timesteps(250)\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "os.makedirs(\"results1\", exist_ok=True)\n",
    "\n",
    "for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    \n",
    "    alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "    \n",
    "    x0_hat = (input - (1 - alpha_cumprod_t).sqrt() * noisy_residual) / alpha_cumprod_t.sqrt()\n",
    "    \n",
    "    # visualize\n",
    "    shape = x0_hat.shape\n",
    "    white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "    result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0_hat.cpu()], dim=3)\n",
    "    savefig(result, f\"results1/img{index}.png\")\n",
    "    \n",
    "    input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "\n",
    "savefig(input, \"final1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90205e21",
   "metadata": {},
   "source": [
    "### Optional\n",
    "æˆ‘ä»¬å¯ä»¥ä»Žç”Ÿæˆçš„ç»“æžœä¸­ï¼ŒæŒ‘é€‰ä¸€éƒ¨åˆ†stepsï¼Œç²˜è´´åœ¨ä¸€èµ·ï¼Œæ–¹ä¾¿å¯è§†åŒ–Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bafc2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‹¼æŽ¥å®Œæˆï¼Œå·²ä¿å­˜è‡³ output.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_list = ['results3/final-%03d.png'%(index*50) for index in range(1, 6)]\n",
    "\n",
    "\n",
    "def vertical_stitch(image_paths, output_path):\n",
    "    images = [add_text_to_image(path, None, path[9:-4], False) for path in image_paths]\n",
    "    \n",
    "    widths = [img.width for img in images]\n",
    "    if len(set(widths)) > 1:\n",
    "        raise ValueError(\"æ‰€æœ‰å›¾ç‰‡çš„å®½åº¦å¿…é¡»ä¸€è‡´\")\n",
    "    \n",
    "    total_height = sum(img.height for img in images)\n",
    "    width = images[0].width \n",
    "\n",
    "    new_image = Image.new('RGB', (width, total_height))\n",
    "    \n",
    "    current_height = 0\n",
    "    for img in images:\n",
    "        new_image.paste(img, (0, current_height))\n",
    "        current_height += img.height\n",
    "    \n",
    "    new_image.save(output_path)\n",
    "    print(f\"æ‹¼æŽ¥å®Œæˆï¼Œå·²ä¿å­˜è‡³ {output_path}\")\n",
    "\n",
    "\n",
    "vertical_stitch(img_list, \"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127265c",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°† $x_0$ å›ºå®šä½ï¼Œè¿›è¡Œè¯•éªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74832d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "scheduler.set_timesteps(250)\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "x0 = Image.open(\"final1.png\")\n",
    "to_tensor = transforms.ToTensor()\n",
    "x0 = to_tensor(x0)\n",
    "x0 = x0*2-1\n",
    "x0 = x0.to(\"cuda\").unsqueeze(0)\n",
    "\n",
    "os.makedirs(\"results2\", exist_ok=True)\n",
    "\n",
    "for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "    alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = (input-alpha_cumprod_t.sqrt()*x0)/(1-alpha_cumprod_t).sqrt()\n",
    "    \n",
    "    shape = x0.shape\n",
    "    white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "    result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0.cpu()], dim=-1)\n",
    "    savefig(result, f\"results2/img{index}.png\")\n",
    "    \n",
    "    input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "\n",
    "savefig(input, \"final2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444d46",
   "metadata": {},
   "source": [
    "### Exper2\n",
    "æŽ¥ä¸‹æ¥æˆ‘ä»¬å°†æŽ¢ç´¢å½“ denoise steps æ”¹å˜æ—¶ï¼Œå›¾åƒç”Ÿæˆè´¨é‡ä¼šå‘ç”Ÿæ€Žæ ·çš„æ”¹å˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(scheduler, input, model, save_dir=None, is_record=False)->torch.tensor:\n",
    "    assert save_dir, \"Please write down save dir!\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for index, t in tqdm(enumerate(scheduler.timesteps)):\n",
    "        with torch.no_grad():\n",
    "            noisy_residual = model(input, t).sample\n",
    "        \n",
    "        if is_record:\n",
    "            alpha_cumprod_t = scheduler.alphas_cumprod[t].to(\"cuda\")\n",
    "            x0_hat = (input - (1 - alpha_cumprod_t).sqrt() * noisy_residual) / alpha_cumprod_t.sqrt()\n",
    "            # visualize\n",
    "            shape = x0_hat.shape\n",
    "            white = torch.ones((shape[0], shape[1], shape[2], 10))\n",
    "            result = torch.cat([input.cpu(), white, noisy_residual.cpu(), white, x0_hat.cpu()], dim=3)\n",
    "            savefig(result, os.path.join(save_dir, \"/img%03d.png\"%(index)))\n",
    "        \n",
    "        input = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(46)\n",
    "\n",
    "timesteps = [index for index in range(250, 0, -50)]\n",
    "input = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
    "\n",
    "for timestep in tqdm(timesteps):\n",
    "    scheduler.set_timesteps(timestep)\n",
    "    output = sample(scheduler, input, model, \"results3\", False)\n",
    "    savefig(output, \"results3/final-%03d.png\"%(timestep))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
